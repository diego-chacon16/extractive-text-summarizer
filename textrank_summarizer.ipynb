{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755fe7e7-3bfd-4331-a547-6d993eae538f",
   "metadata": {},
   "source": [
    "# Extractive Text Summarizer using TextRank\n",
    "\n",
    "## Text Summarization with TF-IDF\n",
    "\n",
    "+ Split document into sentences\n",
    "+ Compute TF-IDF Matrix (Sentences x Terms)\n",
    "+ Score each sentence (average of non-zero TF-IDF components)\n",
    "+ Take the top scoring sentences\n",
    "+ TextRank is an alternative method of scoring each sentence, all other steps remain\n",
    "+ Goal: score each sentence, and utilize cosine similarity to measure the similary to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f43959d-27b4-4795-be5c-f2b6aed567f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japan narrowly escapes recession\\n\\nJapan's ec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jobs growth still slow in the US\\n\\nThe US cre...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India calls for fair trade rules\\n\\nIndia, whi...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ethiopia's crop production up 24%\\n\\nEthiopia ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Court rejects $280bn tobacco case\\n\\nA US gove...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n",
       "5  Japan narrowly escapes recession\\n\\nJapan's ec...  business\n",
       "6  Jobs growth still slow in the US\\n\\nThe US cre...  business\n",
       "7  India calls for fair trade rules\\n\\nIndia, whi...  business\n",
       "8  Ethiopia's crop production up 24%\\n\\nEthiopia ...  business\n",
       "9  Court rejects $280bn tobacco case\\n\\nA US gove...  business"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "\n",
    "df = pd.read_csv('data/bbc_text.csv') # importing bbc_text dataset\n",
    "df.head(10) # getting the first ten rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69027d88-87c9-4541-911c-d8b398b5ece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2225 non-null   object\n",
      " 1   labels  2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c064d45d-161a-46cc-a7de-c5c7c15ec1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df[df['labels'] == 'business']['text'].sample(random_state = 42) # filtering out labels that are not business and grabbing a random simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0061cde-2fd3-4538-bd1f-33a013c76743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using textwrap make the text more visually appealing\n",
    "\n",
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace = False, fix_sentence_endings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6650319-c4ab-46a0-ba20-eaf5cb7a3f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christmas sales worst since 1981\n",
      "\n",
      "UK retail sales fell in December,\n",
      "failing to meet expectations and making it by some counts the worst\n",
      "Christmas since 1981.\n",
      "\n",
      "Retail sales dropped by 1% on the month in\n",
      "December, after a 0.6% rise in November, the Office for National\n",
      "Statistics (ONS) said.  The ONS revised the annual 2004 rate of growth\n",
      "down from the 5.9% estimated in November to 3.2%. A number of\n",
      "retailers have already reported poor figures for December.  Clothing\n",
      "retailers and non-specialist stores were the worst hit with only\n",
      "internet retailers showing any significant growth, according to the\n",
      "ONS.\n",
      "\n",
      "The last time retailers endured a tougher Christmas was 23 years\n",
      "previously, when sales plunged 1.7%.\n",
      "\n",
      "The ONS echoed an earlier\n",
      "caution from Bank of England governor Mervyn King not to read too much\n",
      "into the poor December figures.  Some analysts put a positive gloss on\n",
      "the figures, pointing out that the non-seasonally-adjusted figures\n",
      "showed a performance comparable with 2003. The November-December jump\n",
      "last year was roughly comparable with recent averages, although some\n",
      "way below the serious booms seen in the 1990s.  And figures for retail\n",
      "volume outperformed measures of actual spending, an indication that\n",
      "consumers are looking for bargains, and retailers are cutting their\n",
      "prices.\n",
      "\n",
      "However, reports from some High Street retailers highlight\n",
      "the weakness of the sector.  Morrisons, Woolworths, House of Fraser,\n",
      "Marks & Spencer and Big Food all said that the festive period was\n",
      "disappointing.\n",
      "\n",
      "And a British Retail Consortium survey found that\n",
      "Christmas 2004 was the worst for 10 years.  Yet, other retailers -\n",
      "including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that\n",
      "festive sales were well up on last year.  Investec chief economist\n",
      "Philip Shaw said he did not expect the poor retail figures to have any\n",
      "immediate effect on interest rates.  \"The retail sales figures are\n",
      "very weak, but as Bank of England governor Mervyn King indicated last\n",
      "night, you don't really get an accurate impression of Christmas\n",
      "trading until about Easter,\" said Mr Shaw.  \"Our view is the Bank of\n",
      "England will keep its powder dry and wait to see the big picture.\"\n"
     ]
    }
   ],
   "source": [
    "print(wrap(doc.iloc[0])) # printing out the first article from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e55cfc7-549b-4822-8614-10697c508bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(doc.iloc[0].split('\\n', 1)[1]) # tokenizing the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54285f06-4e07-4ceb-9ea3-848adc21819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = TfidfVectorizer(stop_words = stopwords.words('english'), norm = 'l1') # creating the featurizer and doing minor feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e5c1ad-6100-4809-803f-b14d264ad8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featurizer.fit_transform(sents) # fitting to the data and then transforming it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d714832-8edb-4979-9eed-adffcfb37f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25b1ed86-3997-4816-b7db-15e484b3ddac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 17)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da58da89-de53-4b4a-b445-3afe2770b85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40fd1b28-e6de-4f4d-bdb3-2a630be6dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing similarity matrix\n",
    "# keepdims == true is done so that the result is a 2D matrix which ensures numpy broadcasting operates correctly\n",
    "\n",
    "S /= S.sum(axis= 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62399e16-8a00-4b20-9ddd-dcf4063af5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34aebb2d-a5ba-4fca-a20b-ca5eabea4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform transition matrix\n",
    "# matrix of ones divided by the number of sentences\n",
    "\n",
    "U = np.ones_like(S) / len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc3c51ee-46fd-4db3-a3f0-47241720ef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if the sum of the first row is one\n",
    "\n",
    "U[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8abe417a-2bb4-4f90-840b-6b22fc3c03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothed similarity matrix\n",
    "# compute final matrix - convex combination of S and U\n",
    "# 85% of S and 15% of U - must add to 1\n",
    "\n",
    "factor = 0.15\n",
    "S = (1 - factor) * S + factor * U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97ba0679-7d66-4a67-be0d-e05154bbb63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensuring S is still 1\n",
    "\n",
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd60bbf3-d3c3-4fa2-9ff3-b9ba6522e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the limiting / stationary distribution\n",
    "# transposing the matrix\n",
    "# getting both eigenvalues and eigenvectors\n",
    "\n",
    "eigenvals, eigenvecs = np.linalg.eig(S.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d90028ae-fafe-45da-b173-269625f8529d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.24245466, 0.72108199, 0.67644122, 0.34790129,\n",
       "       0.34417302, 0.3866884 , 0.40333562, 0.41608572, 0.44238593,\n",
       "       0.63909999, 0.62556792, 0.58922572, 0.57452382, 0.48511399,\n",
       "       0.51329157, 0.52975372])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c25a476-e6a7-4f21-b74c-c0be3fa49d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24206557, -0.27051337, -0.2213806 , -0.28613638, -0.25065894,\n",
       "       -0.2499217 , -0.279622  , -0.21515455, -0.2226665 , -0.22745415,\n",
       "       -0.2059112 , -0.20959727, -0.23526242, -0.24203809, -0.23663025,\n",
       "       -0.2940483 , -0.20865607])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the result is the same, then it is a proper eigenvector\n",
    "\n",
    "eigenvecs[:, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3fac843-7016-453f-abfc-82b9b96a710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24206557, -0.27051337, -0.2213806 , -0.28613638, -0.25065894,\n",
       "       -0.2499217 , -0.279622  , -0.21515455, -0.2226665 , -0.22745415,\n",
       "       -0.2059112 , -0.20959727, -0.23526242, -0.24203809, -0.23663025,\n",
       "       -0.2940483 , -0.20865607])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:, 0].dot(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5fe62bf-d98a-4dfd-8490-2f892de1e967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05907327, 0.06601563, 0.05402535, 0.06982824, 0.06117038,\n",
       "       0.06099047, 0.06823848, 0.05250595, 0.05433915, 0.05550753,\n",
       "       0.05025022, 0.05114976, 0.05741304, 0.05906657, 0.05774684,\n",
       "       0.07175905, 0.05092007])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:, 0] / eigenvecs[:, 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2db3dbf3-1ac2-40a3-88e0-16e3ef784ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "limiting_dist = np.ones(len(S)) / len(S) # initializing limiting distribution to be uniform distribution\n",
    "threshold = 1e-8 # defining a threshold tenths to the minus 8, used to quit the loop\n",
    "delta = float('inf') # to the infinity, it will store how much the distribution has changed\n",
    "iters = 0 # keeping track of the iterations\n",
    "while delta > threshold: # as long as delta is bigger than the threshold, the loop will continue to run\n",
    "    iters += 1 # increment iters by 1\n",
    "    \n",
    "    # Markov transition\n",
    "    # computing distribution for the next step stored in p\n",
    "    p = limiting_dist.dot(S)\n",
    "    \n",
    "    # compute change in limiting distribution\\\n",
    "    # sum of absolute differences between old and new distribution\n",
    "    delta = np.abs(p - limiting_dist).sum()\n",
    "    \n",
    "    # update limiting distribution\n",
    "    limiting_dist = p\n",
    "    \n",
    "print(iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7353b59-dc97-4243-ac6e-60df19050671",
   "metadata": {},
   "source": [
    "### This only took 41 steps to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c678df33-8398-4d57-898d-f122ecc17f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05907327, 0.06601563, 0.05402534, 0.06982824, 0.06117038,\n",
       "       0.06099047, 0.06823848, 0.05250595, 0.05433915, 0.05550753,\n",
       "       0.05025022, 0.05114977, 0.05741304, 0.05906657, 0.05774685,\n",
       "       0.07175905, 0.05092008])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out limiting distribution\n",
    "\n",
    "limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c2b1cb5-f553-4dcc-b3cc-be16c84c9c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999982"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbf1e9bb-886a-482c-8298-64fab2d94dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9964738806610427e-08"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(eigenvecs[:, 0] / eigenvecs[:, 0].sum() - limiting_dist).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "731772c0-3504-4efc-a765-a34e5f2ecac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "408fa16c-9249-49c5-95cb-3efa024ba440",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "450be08b-93dd-4898-924f-792970bf2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "0.07 \"The retail sales figures are very weak, but as Bank of England\n",
      "governor Mervyn King indicated last night, you don't really get an\n",
      "accurate impression of Christmas trading until about Easter,\" said Mr\n",
      "Shaw.\n",
      "0.07 A number of retailers have already reported poor figures for\n",
      "December.\n",
      "0.07 The ONS echoed an earlier caution from Bank of England governor\n",
      "Mervyn King not to read too much into the poor December figures.\n",
      "0.07 Retail sales dropped by 1% on the month in December, after a 0.6%\n",
      "rise in November, the Office for National Statistics (ONS) said.\n",
      "0.06 Clothing retailers and non-specialist stores were the worst hit\n",
      "with only internet retailers showing any significant growth, according\n",
      "to the ONS.\n"
     ]
    }
   ],
   "source": [
    "# printing out an extractive summary\n",
    "# since newspapers tend to begin with specifics first and generalizing after, it is important to ensure the text is in order\n",
    "# this way, it lessens the likelihood of any important details being left out\n",
    "\n",
    "print('Generated Summary:')\n",
    "for i in sort_idx[:5]:\n",
    "    print(wrap(\"%.2f %s\" % (scores[i], sents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04285c4b-aeb9-46f0-acf3-392dfa2fca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Christmas sales worst since 1981'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split('\\n')[0] # getting the article title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
