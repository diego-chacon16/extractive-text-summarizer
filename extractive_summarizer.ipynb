{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d918e402-211c-4e52-b4c3-d27c0c608a56",
   "metadata": {},
   "source": [
    "# Extractive Text Summarizer\n",
    "\n",
    "## Text Summarization with TF-IDF\n",
    "\n",
    "+ High-level outline\n",
    "+ Split the document into sentences\n",
    "+ Score each sentence\n",
    "+ Rank each sentence by those score\n",
    "+ Summary = Top scoring sentences\n",
    "\n",
    "## Approach\n",
    "\n",
    "+ Sentence tokenization (splitting the document into sentences) with NLTK\n",
    "+ Build TD-IDF matrix, treating each sentence as if they were documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e1f57c-9fbf-43b3-8c8a-5cd4a46c93d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japan narrowly escapes recession\\n\\nJapan's ec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jobs growth still slow in the US\\n\\nThe US cre...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India calls for fair trade rules\\n\\nIndia, whi...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ethiopia's crop production up 24%\\n\\nEthiopia ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Court rejects $280bn tobacco case\\n\\nA US gove...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n",
       "5  Japan narrowly escapes recession\\n\\nJapan's ec...  business\n",
       "6  Jobs growth still slow in the US\\n\\nThe US cre...  business\n",
       "7  India calls for fair trade rules\\n\\nIndia, whi...  business\n",
       "8  Ethiopia's crop production up 24%\\n\\nEthiopia ...  business\n",
       "9  Court rejects $280bn tobacco case\\n\\nA US gove...  business"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/bbc_text.csv') # importin csv into pandas dataframe \n",
    "df.head(10) # looking at the first ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e89560-c35f-4d68-89fb-587cc2441b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2225 non-null   object\n",
      " 1   labels  2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# understanding the landscape quickly before starting the project\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b83e3c-21b6-4612-88af-456c820075fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df[df['labels'] == 'business']['text'].sample(random_state = 42) # filtering out labels that are not business and grabbing a random simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250906ae-c63b-44b7-95c3-6bbaeb1e739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using textwrap make the text more visually appealing\n",
    "\n",
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace = False, fix_sentence_endings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd54274-6cc0-462d-b07d-845400e74e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christmas sales worst since 1981\n",
      "\n",
      "UK retail sales fell in December,\n",
      "failing to meet expectations and making it by some counts the worst\n",
      "Christmas since 1981.\n",
      "\n",
      "Retail sales dropped by 1% on the month in\n",
      "December, after a 0.6% rise in November, the Office for National\n",
      "Statistics (ONS) said.  The ONS revised the annual 2004 rate of growth\n",
      "down from the 5.9% estimated in November to 3.2%. A number of\n",
      "retailers have already reported poor figures for December.  Clothing\n",
      "retailers and non-specialist stores were the worst hit with only\n",
      "internet retailers showing any significant growth, according to the\n",
      "ONS.\n",
      "\n",
      "The last time retailers endured a tougher Christmas was 23 years\n",
      "previously, when sales plunged 1.7%.\n",
      "\n",
      "The ONS echoed an earlier\n",
      "caution from Bank of England governor Mervyn King not to read too much\n",
      "into the poor December figures.  Some analysts put a positive gloss on\n",
      "the figures, pointing out that the non-seasonally-adjusted figures\n",
      "showed a performance comparable with 2003. The November-December jump\n",
      "last year was roughly comparable with recent averages, although some\n",
      "way below the serious booms seen in the 1990s.  And figures for retail\n",
      "volume outperformed measures of actual spending, an indication that\n",
      "consumers are looking for bargains, and retailers are cutting their\n",
      "prices.\n",
      "\n",
      "However, reports from some High Street retailers highlight\n",
      "the weakness of the sector.  Morrisons, Woolworths, House of Fraser,\n",
      "Marks & Spencer and Big Food all said that the festive period was\n",
      "disappointing.\n",
      "\n",
      "And a British Retail Consortium survey found that\n",
      "Christmas 2004 was the worst for 10 years.  Yet, other retailers -\n",
      "including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that\n",
      "festive sales were well up on last year.  Investec chief economist\n",
      "Philip Shaw said he did not expect the poor retail figures to have any\n",
      "immediate effect on interest rates.  \"The retail sales figures are\n",
      "very weak, but as Bank of England governor Mervyn King indicated last\n",
      "night, you don't really get an accurate impression of Christmas\n",
      "trading until about Easter,\" said Mr Shaw.  \"Our view is the Bank of\n",
      "England will keep its powder dry and wait to see the big picture.\"\n"
     ]
    }
   ],
   "source": [
    "print(wrap(doc.iloc[0])) # printing out the first article from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2334a536-42a2-447c-813f-df2b41dfd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(doc.iloc[0].split('\\n', 1)[1]) # tokenizing the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "251359ff-d662-4f3f-87ca-af43271bcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = TfidfVectorizer(stop_words = stopwords.words('english'), norm = 'l1') # creating the featurizer and doing minor feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857a9cc4-7000-48b8-ad14-a0e5cecd20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featurizer.fit_transform(sents) # fitting to the data and then transforming it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53e7e22-c231-4e6f-a652-322b0675908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a function to score the sentence given its tfidf representation\n",
    "\n",
    "def get_sentence_score(tfidf_row):\n",
    "    # return the average of the non zero values\n",
    "    # of the tf-idf vector representation of a sentence\n",
    "    x = tfidf_row[tfidf_row != 0] \n",
    "    return x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d401bf6d-d3a1-4703-b338-6e38b53e3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the scores for each sentence and storing it in a variable\n",
    "\n",
    "scores = np.zeros(len(sents))\n",
    "\n",
    "# running a for loop to go through each index until the length of sentences has been completed\n",
    "\n",
    "for i in range(len(sents)):\n",
    "    score = get_sentence_score(X[i,:]) # getting the score from each index\n",
    "    scores[i] = score # return the score for the i the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2870e04-1151-48c9-8424-16af8cd7d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the scores\n",
    "# negating scores so it begins descending rather than ascending\n",
    "\n",
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eec22d-ac8d-4f7e-9077-24cc1581c309",
   "metadata": {},
   "source": [
    "## Many options for how to choose which sentences to include:\n",
    "\n",
    "+ 1. top N sentences\n",
    "+ 2. top N words or characters\n",
    "+ 3. top X% or top X% words\n",
    "+ 4. sentences with scores > average score\n",
    "+ 5. sentences with scores > fsctor * average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f14042c2-1021-4e86-9857-b2ec760eac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "0.14 A number of retailers have already reported poor figures for\n",
      "December.\n",
      "0.13 However, reports from some High Street retailers highlight the\n",
      "weakness of the sector.\n",
      "0.12 The ONS revised the annual 2004 rate of growth down from the 5.9%\n",
      "estimated in November to 3.2%.\n",
      "0.10 \"Our view is the Bank of England will keep its powder dry and\n",
      "wait to see the big picture.\"\n",
      "0.10 And a British Retail Consortium survey found that Christmas 2004\n",
      "was the worst for 10 years.\n"
     ]
    }
   ],
   "source": [
    "# printing out an extractive summary\n",
    "# since newspapers tend to begin with specifics first and generalizing after, it is important to ensure the text is in order\n",
    "# this way, it lessens the likelihood of any important details being left out\n",
    "\n",
    "print('Generated Summary:')\n",
    "for i in sort_idx[:5]:\n",
    "    print(wrap(\"%.2f %s\" % (scores[i], sents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff83a969-269c-4c3a-b6c6-beb5eb287992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Christmas sales worst since 1981'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split('\\n', 1)[0] # printing out the title of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f864fd-b56b-4f0a-8988-0b7b2e0355ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to do all of the steps to perform an extractive summary\n",
    "\n",
    "def summarize(text):\n",
    "    sents = nltk.sent_tokenize(text) #extract sentences\n",
    "    X = featurizer.fit_transform(sents) # perform tf-idf\n",
    "    scores = np.zeros(len(sents)) # compute scores for each sentence\n",
    "    for i in range(len(sents)):\n",
    "        score = get_sentence_score(X[i, :])\n",
    "        scores[i] = score\n",
    "        \n",
    "    sort_idx = np.argsort(-scores) # sort the scores\n",
    "    for i in sort_idx[:5]: # print the first five scores\n",
    "        print(wrap('%.2f: %s' % (scores[i], sents[i]))) # print out the score, as well as the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98434c8e-0318-4102-924f-3c4801541440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11: The Black Eyed Peas won awards for best R 'n' B video and\n",
      "sexiest video, both for Hey Mama.\n",
      "0.10: The ceremony was held at the Luna Park fairground in Sydney\n",
      "Harbour and was hosted by the Osbourne family.\n",
      "0.10: Goodrem, Green Day and the Black Eyed Peas took home two awards\n",
      "each.\n",
      "0.10: Other winners included Green Day, voted best group, and the\n",
      "Black Eyed Peas.\n",
      "0.10: The VH1 First Music Award went to Cher honouring her\n",
      "achievements within the music industry.\n"
     ]
    }
   ],
   "source": [
    "# filtering out by entertainment, getting a random sample and running the summarize function to see how it performs\n",
    "\n",
    "doc = df[df['labels'] == 'entertainment']['text'].sample(random_state = 123)\n",
    "summarize(doc.iloc[0].split('\\n', 1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1f15d-883b-4cb3-b0ef-bc969d8d7c10",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "+ 1. The summary does a good job of informing the reader of the purpose of the article\n",
    "+ 2. However, there are some key details left out, such as: What event was this? Where was it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155ffa75-c10e-436e-a340-ddb665ea054c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goodrem wins top female MTV prize'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the title from the article\n",
    "\n",
    "doc.iloc[0].split('\\n', 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a799901-533a-4039-85e2-c847e1b2d256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodrem wins top female MTV prize\n",
      "\n",
      "Pop singer Delta Goodrem has\n",
      "scooped one of the top individual prizes at the first Australian MTV\n",
      "Music Awards.\n",
      "\n",
      "The 21-year-old singer won the award for best female\n",
      "artist, with Australian Idol runner-up Shannon Noll taking the title\n",
      "of best male at the ceremony.  Goodrem, known in both Britain and\n",
      "Australia for her role as Nina Tucker in TV soap Neighbours, also\n",
      "performed a duet with boyfriend Brian McFadden.  Other winners\n",
      "included Green Day, voted best group, and the Black Eyed Peas.\n",
      "Goodrem, Green Day and the Black Eyed Peas took home two awards each.\n",
      "As well as best female, Goodrem also took home the Pepsi Viewers\n",
      "Choice Award, whilst Green Day bagged the prize for best rock video\n",
      "for American Idiot.  The Black Eyed Peas won awards for best R 'n' B\n",
      "video and sexiest video, both for Hey Mama.  Local singer and\n",
      "songwriter Missy Higgins took the title of breakthrough artist of the\n",
      "year, with Australian Idol winner Guy Sebastian taking the honours for\n",
      "best pop video.  The VH1 First Music Award went to Cher honouring her\n",
      "achievements within the music industry.  The ceremony was held at the\n",
      "Luna Park fairground in Sydney Harbour and was hosted by the Osbourne\n",
      "family.  Artists including Carmen Electra, Missy Higgins, Kelly\n",
      "Osbourne, Green Day, Ja Rule and Natalie Imbruglia gave live\n",
      "performances at the event.\n"
     ]
    }
   ],
   "source": [
    "# getting the whole article\n",
    "\n",
    "print(wrap(doc.iloc[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d218f3-bb13-4556-9343-3e0c0c904949",
   "metadata": {},
   "source": [
    "### We now know that the event was the first Australian MTV Words\n",
    "\n",
    "### Next steps: Attempt an extractive summary using TextRank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
